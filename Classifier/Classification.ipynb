{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68941c53",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b3873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.30754766\n",
      "Iteration 2, loss = 1.30467584\n",
      "Iteration 3, loss = 1.30056534\n",
      "Iteration 4, loss = 1.29510781\n",
      "Iteration 5, loss = 1.28822208\n",
      "Iteration 6, loss = 1.28029002\n",
      "Iteration 7, loss = 1.27134261\n",
      "Iteration 8, loss = 1.26133661\n",
      "Iteration 9, loss = 1.24989150\n",
      "Iteration 10, loss = 1.23707613\n",
      "Iteration 11, loss = 1.22258082\n",
      "Iteration 12, loss = 1.20645210\n",
      "Iteration 13, loss = 1.18875335\n",
      "Iteration 14, loss = 1.16968755\n",
      "Iteration 15, loss = 1.14784424\n",
      "Iteration 16, loss = 1.12380455\n",
      "Iteration 17, loss = 1.09800069\n",
      "Iteration 18, loss = 1.06911769\n",
      "Iteration 19, loss = 1.03922874\n",
      "Iteration 20, loss = 1.00936330\n",
      "Iteration 21, loss = 0.97974778\n",
      "Iteration 22, loss = 0.95050338\n",
      "Iteration 23, loss = 0.92248501\n",
      "Iteration 24, loss = 0.89558599\n",
      "Iteration 25, loss = 0.87029879\n",
      "Iteration 26, loss = 0.84683630\n",
      "Iteration 27, loss = 0.82552452\n",
      "Iteration 28, loss = 0.80628168\n",
      "Iteration 29, loss = 0.78871335\n",
      "Iteration 30, loss = 0.77271269\n",
      "Iteration 31, loss = 0.75793216\n",
      "Iteration 32, loss = 0.74409820\n",
      "Iteration 33, loss = 0.73115201\n",
      "Iteration 34, loss = 0.71894918\n",
      "Iteration 35, loss = 0.70738810\n",
      "Iteration 36, loss = 0.69639637\n",
      "Iteration 37, loss = 0.68567347\n",
      "Iteration 38, loss = 0.67516708\n",
      "Iteration 39, loss = 0.66479238\n",
      "Iteration 40, loss = 0.65444654\n",
      "Iteration 41, loss = 0.64406999\n",
      "Iteration 42, loss = 0.63372360\n",
      "Iteration 43, loss = 0.62309047\n",
      "Iteration 44, loss = 0.61234917\n",
      "Iteration 45, loss = 0.60147383\n",
      "Iteration 46, loss = 0.59050669\n",
      "Iteration 47, loss = 0.57938313\n",
      "Iteration 48, loss = 0.56811347\n",
      "Iteration 49, loss = 0.55678910\n",
      "Iteration 50, loss = 0.54534594\n",
      "Iteration 51, loss = 0.53386934\n",
      "Iteration 52, loss = 0.52246608\n",
      "Iteration 53, loss = 0.51116916\n",
      "Iteration 54, loss = 0.49989618\n",
      "Iteration 55, loss = 0.48872940\n",
      "Iteration 56, loss = 0.47776825\n",
      "Iteration 57, loss = 0.46700858\n",
      "Iteration 58, loss = 0.45654610\n",
      "Iteration 59, loss = 0.44645514\n",
      "Iteration 60, loss = 0.43682915\n",
      "Iteration 61, loss = 0.42751758\n",
      "Iteration 62, loss = 0.41853988\n",
      "Iteration 63, loss = 0.40986355\n",
      "Iteration 64, loss = 0.40153960\n",
      "Iteration 65, loss = 0.39352131\n",
      "Iteration 66, loss = 0.38591482\n",
      "Iteration 67, loss = 0.37859733\n",
      "Iteration 68, loss = 0.37158100\n",
      "Iteration 69, loss = 0.36482836\n",
      "Iteration 70, loss = 0.35839327\n",
      "Iteration 71, loss = 0.35223566\n",
      "Iteration 72, loss = 0.34631065\n",
      "Iteration 73, loss = 0.34060889\n",
      "Iteration 74, loss = 0.33517318\n",
      "Iteration 75, loss = 0.32993241\n",
      "Iteration 76, loss = 0.32487151\n",
      "Iteration 77, loss = 0.31997714\n",
      "Iteration 78, loss = 0.31523466\n",
      "Iteration 79, loss = 0.31064221\n",
      "Iteration 80, loss = 0.30622218\n",
      "Iteration 81, loss = 0.30192653\n",
      "Iteration 82, loss = 0.29775218\n",
      "Iteration 83, loss = 0.29369268\n",
      "Iteration 84, loss = 0.28973222\n",
      "Iteration 85, loss = 0.28586458\n",
      "Iteration 86, loss = 0.28208121\n",
      "Iteration 87, loss = 0.27837475\n",
      "Iteration 88, loss = 0.27475886\n",
      "Iteration 89, loss = 0.27122884\n",
      "Iteration 90, loss = 0.26776121\n",
      "Iteration 91, loss = 0.26433419\n",
      "Iteration 92, loss = 0.26096284\n",
      "Iteration 93, loss = 0.25769377\n",
      "Iteration 94, loss = 0.25448510\n",
      "Iteration 95, loss = 0.25133538\n",
      "Iteration 96, loss = 0.24823396\n",
      "Iteration 97, loss = 0.24518546\n",
      "Iteration 98, loss = 0.24219083\n",
      "Iteration 99, loss = 0.23925433\n",
      "Iteration 100, loss = 0.23637363\n",
      "Iteration 101, loss = 0.23354441\n",
      "Iteration 102, loss = 0.23076483\n",
      "Iteration 103, loss = 0.22803666\n",
      "Iteration 104, loss = 0.22536943\n",
      "Iteration 105, loss = 0.22275873\n",
      "Iteration 106, loss = 0.22019789\n",
      "Iteration 107, loss = 0.21769043\n",
      "Iteration 108, loss = 0.21524541\n",
      "Iteration 109, loss = 0.21286791\n",
      "Iteration 110, loss = 0.21054965\n",
      "Iteration 111, loss = 0.20827769\n",
      "Iteration 112, loss = 0.20605153\n",
      "Iteration 113, loss = 0.20388017\n",
      "Iteration 114, loss = 0.20177484\n",
      "Iteration 115, loss = 0.19972270\n",
      "Iteration 116, loss = 0.19771064\n",
      "Iteration 117, loss = 0.19573718\n",
      "Iteration 118, loss = 0.19380200\n",
      "Iteration 119, loss = 0.19192727\n",
      "Iteration 120, loss = 0.19008757\n",
      "Iteration 121, loss = 0.18828281\n",
      "Iteration 122, loss = 0.18651193\n",
      "Iteration 123, loss = 0.18477395\n",
      "Iteration 124, loss = 0.18306811\n",
      "Iteration 125, loss = 0.18139370\n",
      "Iteration 126, loss = 0.17975002\n",
      "Iteration 127, loss = 0.17813640\n",
      "Iteration 128, loss = 0.17655217\n",
      "Iteration 129, loss = 0.17499669\n",
      "Iteration 130, loss = 0.17346932\n",
      "Iteration 131, loss = 0.17196934\n",
      "Iteration 132, loss = 0.17049898\n",
      "Iteration 133, loss = 0.16905784\n",
      "Iteration 134, loss = 0.16765883\n",
      "Iteration 135, loss = 0.16632183\n",
      "Iteration 136, loss = 0.16500814\n",
      "Iteration 137, loss = 0.16371684\n",
      "Iteration 138, loss = 0.16244733\n",
      "Iteration 139, loss = 0.16119905\n",
      "Iteration 140, loss = 0.15997336\n",
      "Iteration 141, loss = 0.15877778\n",
      "Iteration 142, loss = 0.15760161\n",
      "Iteration 143, loss = 0.15644443\n",
      "Iteration 144, loss = 0.15530580\n",
      "Iteration 145, loss = 0.15418525\n",
      "Iteration 146, loss = 0.15308235\n",
      "Iteration 147, loss = 0.15199653\n",
      "Iteration 148, loss = 0.15092745\n",
      "Iteration 149, loss = 0.14987465\n",
      "Iteration 150, loss = 0.14883757\n",
      "Iteration 151, loss = 0.14782102\n",
      "Iteration 152, loss = 0.14681961\n",
      "Iteration 153, loss = 0.14582811\n",
      "Iteration 154, loss = 0.14484793\n",
      "Iteration 155, loss = 0.14388129\n",
      "Iteration 156, loss = 0.14292795\n",
      "Iteration 157, loss = 0.14198766\n",
      "Iteration 158, loss = 0.14106016\n",
      "Iteration 159, loss = 0.14014492\n",
      "Iteration 160, loss = 0.13924180\n",
      "Iteration 161, loss = 0.13835096\n",
      "Iteration 162, loss = 0.13747382\n",
      "Iteration 163, loss = 0.13661018\n",
      "Iteration 164, loss = 0.13575990\n",
      "Iteration 165, loss = 0.13492103\n",
      "Iteration 166, loss = 0.13409416\n",
      "Iteration 167, loss = 0.13327839\n",
      "Iteration 168, loss = 0.13247323\n",
      "Iteration 169, loss = 0.13167845\n",
      "Iteration 170, loss = 0.13089384\n",
      "Iteration 171, loss = 0.13011919\n",
      "Iteration 172, loss = 0.12935429\n",
      "Iteration 173, loss = 0.12859894\n",
      "Iteration 174, loss = 0.12785294\n",
      "Iteration 175, loss = 0.12711612\n",
      "Iteration 176, loss = 0.12638828\n",
      "Iteration 177, loss = 0.12566926\n",
      "Iteration 178, loss = 0.12495887\n",
      "Iteration 179, loss = 0.12425695\n",
      "Iteration 180, loss = 0.12356410\n",
      "Iteration 181, loss = 0.12287841\n",
      "Iteration 182, loss = 0.12220072\n",
      "Iteration 183, loss = 0.12153210\n",
      "Iteration 184, loss = 0.12087118\n",
      "Iteration 185, loss = 0.12021772\n",
      "Iteration 186, loss = 0.11957209\n",
      "Iteration 187, loss = 0.11893325\n",
      "Iteration 188, loss = 0.11830174\n",
      "Iteration 189, loss = 0.11767723\n",
      "Iteration 190, loss = 0.11705995\n",
      "Iteration 191, loss = 0.11644905\n",
      "Iteration 192, loss = 0.11584494\n",
      "Iteration 193, loss = 0.11524772\n",
      "Iteration 194, loss = 0.11465684\n",
      "Iteration 195, loss = 0.11407285\n",
      "Iteration 196, loss = 0.11349522\n",
      "Iteration 197, loss = 0.11292369\n",
      "Iteration 198, loss = 0.11235821\n",
      "Iteration 199, loss = 0.11179879\n",
      "Iteration 200, loss = 0.11124517\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.163188      0.014043         0.002519        0.000806   \n",
      "1        0.139110      0.004370         0.002062        0.000494   \n",
      "2        0.148106      0.006061         0.002280        0.000602   \n",
      "3        0.137343      0.005739         0.002082        0.000395   \n",
      "4        0.156283      0.007133         0.002517        0.000698   \n",
      "5        0.154087      0.010106         0.002502        0.000635   \n",
      "6        0.148993      0.012013         0.002320        0.000615   \n",
      "7        0.168738      0.018439         0.002621        0.000555   \n",
      "8        0.151992      0.009860         0.002279        0.000531   \n",
      "9        0.150050      0.010159         0.002473        0.000685   \n",
      "10       0.155285      0.012814         0.002241        0.000650   \n",
      "11       0.155485      0.022805         0.002361        0.000975   \n",
      "12       0.149834      0.019760         0.002200        0.000939   \n",
      "13       0.159907      0.011840         0.002501        0.000694   \n",
      "14       0.136395      0.012853         0.001880        0.000516   \n",
      "\n",
      "   param_classifier__activation param_classifier__alpha  \\\n",
      "0                          relu                 0.00001   \n",
      "1                          relu                 0.00001   \n",
      "2                          relu                 0.00001   \n",
      "3                          relu                 0.00001   \n",
      "4                          relu                 0.00001   \n",
      "5                          relu                 0.00001   \n",
      "6                          relu                 0.00001   \n",
      "7                          relu                 0.00001   \n",
      "8                          relu                 0.00001   \n",
      "9                          relu                 0.00001   \n",
      "10                         relu                 0.00001   \n",
      "11                         relu                 0.00001   \n",
      "12                         relu                 0.00001   \n",
      "13                         relu                 0.00001   \n",
      "14                         relu                 0.00001   \n",
      "\n",
      "   param_classifier__hidden_layer_sizes param_classifier__learning_rate_init  \\\n",
      "0                                (5, 3)                                0.001   \n",
      "1                                (5, 3)                                0.002   \n",
      "2                                (5, 3)                                0.003   \n",
      "3                                (5, 3)                                0.004   \n",
      "4                                (5, 3)                                0.005   \n",
      "5                                (5, 3)                                0.006   \n",
      "6                                (5, 3)                                0.007   \n",
      "7                                (5, 3)                                0.008   \n",
      "8                                (5, 3)                                0.009   \n",
      "9                                (5, 3)                                 0.01   \n",
      "10                               (5, 3)                                0.011   \n",
      "11                               (5, 3)                                0.012   \n",
      "12                               (5, 3)                                0.013   \n",
      "13                               (5, 3)                                0.014   \n",
      "14                               (5, 3)                                0.015   \n",
      "\n",
      "   param_classifier__solver param_classifier__tol  ... split17_train_score  \\\n",
      "0                       sgd                   0.0  ...            0.859375   \n",
      "1                       sgd                   0.0  ...            0.929688   \n",
      "2                       sgd                   0.0  ...            0.960938   \n",
      "3                       sgd                   0.0  ...            0.968750   \n",
      "4                       sgd                   0.0  ...            0.968750   \n",
      "5                       sgd                   0.0  ...            0.968750   \n",
      "6                       sgd                   0.0  ...            0.976562   \n",
      "7                       sgd                   0.0  ...            0.984375   \n",
      "8                       sgd                   0.0  ...            0.984375   \n",
      "9                       sgd                   0.0  ...            0.984375   \n",
      "10                      sgd                   0.0  ...            0.984375   \n",
      "11                      sgd                   0.0  ...            0.984375   \n",
      "12                      sgd                   0.0  ...            0.984375   \n",
      "13                      sgd                   0.0  ...            0.984375   \n",
      "14                      sgd                   0.0  ...            0.992188   \n",
      "\n",
      "    split18_train_score  split19_train_score  split20_train_score  \\\n",
      "0              0.757812             0.882812             0.773438   \n",
      "1              0.937500             0.953125             0.937500   \n",
      "2              0.960938             0.968750             0.968750   \n",
      "3              0.968750             0.984375             0.984375   \n",
      "4              0.976562             0.984375             0.984375   \n",
      "5              0.976562             0.992188             0.984375   \n",
      "6              0.984375             1.000000             0.984375   \n",
      "7              0.984375             1.000000             0.992188   \n",
      "8              0.992188             1.000000             0.992188   \n",
      "9              0.992188             1.000000             0.992188   \n",
      "10             0.992188             1.000000             0.992188   \n",
      "11             0.992188             1.000000             0.992188   \n",
      "12             0.992188             1.000000             0.992188   \n",
      "13             0.992188             1.000000             0.992188   \n",
      "14             0.992188             1.000000             0.992188   \n",
      "\n",
      "    split21_train_score  split22_train_score  split23_train_score  \\\n",
      "0              0.875000             0.773438             0.835938   \n",
      "1              0.937500             0.953125             0.929688   \n",
      "2              0.960938             0.968750             0.968750   \n",
      "3              0.976562             0.976562             0.976562   \n",
      "4              0.976562             0.976562             0.976562   \n",
      "5              0.984375             0.992188             0.984375   \n",
      "6              0.984375             1.000000             0.984375   \n",
      "7              0.992188             1.000000             0.984375   \n",
      "8              0.992188             1.000000             0.984375   \n",
      "9              0.992188             1.000000             0.984375   \n",
      "10             0.992188             1.000000             0.984375   \n",
      "11             0.992188             1.000000             0.984375   \n",
      "12             0.992188             1.000000             0.984375   \n",
      "13             0.992188             1.000000             0.984375   \n",
      "14             0.992188             1.000000             0.984375   \n",
      "\n",
      "    split24_train_score  mean_train_score  std_train_score  \n",
      "0              0.796875          0.816875         0.047242  \n",
      "1              0.929688          0.940625         0.008268  \n",
      "2              0.953125          0.962812         0.005538  \n",
      "3              0.968750          0.974375         0.006450  \n",
      "4              0.976562          0.980313         0.006297  \n",
      "5              0.984375          0.983437         0.007435  \n",
      "6              0.984375          0.986563         0.007500  \n",
      "7              0.984375          0.988437         0.007369  \n",
      "8              0.984375          0.989375         0.006946  \n",
      "9              0.984375          0.990313         0.006358  \n",
      "10             0.984375          0.991563         0.005376  \n",
      "11             0.992188          0.992500         0.004677  \n",
      "12             0.992188          0.992812         0.004375  \n",
      "13             0.992188          0.993125         0.004026  \n",
      "14             0.992188          0.993437         0.003617  \n",
      "\n",
      "[15 rows x 66 columns]\n",
      "\n",
      "Best Params:\n",
      " {'classifier__activation': 'relu', 'classifier__alpha': 1e-05, 'classifier__hidden_layer_sizes': (5, 3), 'classifier__learning_rate_init': 0.006999999999999998, 'classifier__solver': 'sgd', 'classifier__tol': 1e-08}\n",
      "\n",
      "Best Score:\n",
      " 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BestClassifier.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.neural_network as nn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "path = u\"midterm_hw_dataset/classification/train/3_train_classification.csv\"\n",
    "df = pd.read_csv(path)\n",
    "m, n = df.shape\n",
    "X = df.iloc[:, 0 : n - 1]\n",
    "Y = df.iloc[:, n - 1]\n",
    "X_type = list(X.columns)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "steps = [\n",
    "\t('scaler', StandardScaler()), \n",
    "\t('classifier', nn.MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=rng, early_stopping=False, momentum=0.9, verbose=1))\n",
    "]\n",
    "clf_pipe = Pipeline(steps=steps)\n",
    "\n",
    "params = {\n",
    "\t# 'classifier__max_iter': [200, 500, 1000, 1500, 2000],\n",
    "\t# 'classifier__activation' : ['identity', 'sigmoid', 'tanh', 'relu'],\n",
    "\t'classifier__activation': ['relu'], # 'identity'\n",
    "\t'classifier__solver': ['sgd'], \n",
    "\t'classifier__alpha': [1e-5], # np.logspace(-5, 1, 7), # 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10\n",
    "\t'classifier__learning_rate_init': np.linspace(0.001, 0.015, 15),\n",
    "\t'classifier__tol': [1e-8], # np.logspace(-8, -4, 5),\n",
    "\t# 'classifier__momentum': np.linspace(0.7, 0.9, 21),\n",
    "\t'classifier__hidden_layer_sizes': [(5,3)],\n",
    "\t# 'classifier__hidden_layer_sizes': [(3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,)]\n",
    "\t# 'classifier__hidden_layer_sizes': [(3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,),\n",
    "\t# \t\t\t\t\t\t\t\t(3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 2), (9, 2), (10, 2), (11, 2), (12, 2), (13, 2),\n",
    "\t# \t\t\t\t\t\t\t\t(3, 3), (4, 3), (5, 3), (6, 3), (7, 3), (8, 3), (9, 3), (10, 3), (11, 3), (12, 3), (13, 3),\n",
    "\t# \t\t\t\t\t\t\t\t(3, 4), (4, 4), (5, 4), (6, 4), (7, 4), (8, 4), (9, 4), (10, 4), (11, 4), (12, 4), (13, 4)]\n",
    "\t}\n",
    "grid = GridSearchCV(clf_pipe,  params, scoring='accuracy', n_jobs=8, cv=RepeatedKFold(n_splits=5, n_repeats=5, random_state=rng), return_train_score=True)\n",
    "grid.fit(X, Y)\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "grid_results.to_csv(\"grid_classifier_results.csv\")\n",
    "print(grid_results)\n",
    "print(\"\\nBest Params:\\n\", grid.best_params_)\n",
    "print(\"\\nBest Score:\\n\", grid.best_score_)\n",
    "import joblib\n",
    "joblib.dump(grid, \"Grid_classifier.pkl\")\n",
    "joblib.dump(grid.best_estimator_, \"BestClassifier.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab95bc2",
   "metadata": {},
   "source": [
    "分类器超参数的确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f83148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAd7UlEQVR4nO3de3Sc9X3n8fd3ZjS6X2xJvkpGMjEGQ2xChIGQElJCgimBbXazhU2ayyaHcjbkJOme05Dt5tJmz9m06WaTbS7EJdk0aQLNJjRhWRJC0xDaEAriZmzAIIyNZdmWbCNLlq3LzHz3j2dkxrIsjeyRnplnPq9z5sxz08wHW3zm8e95nnnM3RERkdIXCzuAiIgUhgpdRCQiVOgiIhGhQhcRiQgVuohIRCTCeuOWlhbv6OgI6+1FRErS448/fsDdW6dbF1qhd3R00N3dHdbbi4iUJDPbdap1GnIREYkIFbqISESo0EVEIkKFLiISESp0EZGIUKGLiESECl1EJCJKrtAHhsf43D3bGE9lwo4iIlJUSq7QH335EN95eCd/+fPnw44iIlJUSq7Qf2/9cm68uJ2//e1Odh86GnYcEZGiUXKFDvDxt51DxuEHj74SdhQRkaJRkoW+rLGKK89p5ceP95JKayxdRARKtNABfv+ilfQPj/Hk7sGwo4iIFIWSLfQrzmklETN++Vx/2FFERIpCyRZ6Q1UFGzsX8+B2FbqICORR6Gb2bTPrN7Otp1j/HjPbkn08bGYbCh9zem86u5nn9w0zeHR8od5SRKRo5bOH/h3gmhnWvwy8xd3XA58HNhcgV14u7lgMQPfOVxfqLUVEitashe7uDwGHZlj/sLtPNuojQFuBss1qQ3sTyXiMx3aeMp6ISNko9Bj6h4CfnWqlmd1sZt1m1j0wMHDGb1ZVEefc5fVs7Tt8xq8lIlLqClboZvZWgkL/5Km2cffN7t7l7l2trdPe43TO1i1v4Nm+Idy9IK8nIlKqClLoZrYeuAO4wd0PFuI187VuRQOvHp1g39DoQr6tiEjROeNCN7NVwN3AH7r7C2ceaW7WLW8A4Nm+oYV+axGRopKYbQMzuxO4Emgxs17gs0AFgLvfDnwGaAa+bmYAKXfvmq/AU61ZWg9AT/8Rrjpv6UK9rYhI0Zm10N39plnWfxj4cMESzVFjdQXNtUl2HhwJK4KISFEo2StFc3W01LJjQIUuIuUtEoXe2VLLywdU6CJS3iJT6P3DYxwZS4UdRUQkNJEo9NUttQDs1F66iJSxSBR6Z2tQ6Bp2EZFyFolC72hWoYuIRKLQqyritNQl6Rs8FnYUEZHQRKLQAZY3VtN3WJf/i0j5ikyhr2iqYq/20EWkjEWm0Jc3VrNXe+giUsYiU+grmqo4MpZiaHQi7CgiIqGITKEvb6wGYO+g9tJFpDxFqNCrANh7WOPoIlKeIlPorfWVABw4Mh5yEhGRcESm0FvqJgt9LOQkIiLhiEyh11YmqK6Ic2BYhS4i5SkyhQ7QUp9kQHvoIlKmolXodZUachGRshW9Qh/WQVERKU+RKvTWeu2hi0j5ilSht9RVcujoOKl0JuwoIiILLlKF3lqXxB0OjWjYRUTKT6QKffJcdJ3pIiLlaNZCN7Nvm1m/mW09xXozs/9lZj1mtsXMLip8zPy06GpRESlj+eyhfwe4Zob1m4A12cfNwDfOPNbpOX61qC4uEpEyNGuhu/tDwKEZNrkB+K4HHgGazGx5oQLOxWvf56JCF5HyU4gx9JXA7pz53uyyk5jZzWbWbWbdAwMDBXjrE9Um41RVxBjQHrqIlKFCFLpNs8yn29DdN7t7l7t3tba2FuCtpwQx09WiIlK2ClHovUB7znwb0FeA1z0tQaHroKiIlJ9CFPo9wPuyZ7tcChx2970FeN3T0lpfqSEXESlLidk2MLM7gSuBFjPrBT4LVAC4++3AfcC1QA9wFPjgfIXNR2t9JU/sejXMCCIioZi10N39plnWO/CRgiU6Q63Zy/8n0hkq4pG6bkpEZEaRa7zW+kpd/i8iZSmShQ5oHF1Eyo4KXUQkIqJX6HUqdBEpT9Er9Hp946KIlKfIFXpVRZz6qoT20EWk7ESu0EEXF4lIeYpmodep0EWk/ESz0OsrNYYuImUnkoW+pL6K/UOjBBexioiUh0gW+vLGKo6OpxkeS4UdRURkwUSy0Jc1VgGwd3A05CQiIgsnkoW+oiko9L7Dx0JOIiKycCJZ6MsaqwHYd1h76CJSPiJZ6EvqK4kZ7B3UHrqIlI9IFnpFPEZrfSV7tYcuImUkkoUOsLyxWoUuImUlwoVexV4dFBWRMhLhQg/20HVxkYiUi8gW+oqm4OKiw8cmwo4iIrIgIlvo7YtrANh18GjISUREFkZkC72zpRaAnQdHQk4iIrIwIlvoq7J76DsPaA9dRMpDXoVuZteY2XYz6zGz26ZZ32hm/9fMnjazbWb2wcJHnZuqijjLG6vYpT10ESkTsxa6mcWBrwGbgHXATWa2bspmHwGedfcNwJXA/zCzZIGzzllHc62GXESkbOSzh74R6HH3He4+DtwF3DBlGwfqzcyAOuAQEPp313a01LBTB0VFpEzkU+grgd05873ZZbm+CpwH9AHPAB9z98zUFzKzm82s28y6BwYGTjNy/s5qruXQyLhOXRSRspBPods0y6ZerfMO4ClgBXAh8FUzazjph9w3u3uXu3e1trbOOexcdTRnz3Q5oGEXEYm+fAq9F2jPmW8j2BPP9UHgbg/0AC8D5xYm4ulbs7QOgBf2D4ecRERk/uVT6I8Ba8ysM3ug80bgninbvAJcBWBmS4G1wI5CBj0dHc21VCZibN+nQheR6EvMtoG7p8zsVuB+IA582923mdkt2fW3A58HvmNmzxAM0XzS3Q/MY+68xGPGmqV1bNceuoiUgVkLHcDd7wPum7Ls9pzpPuDthY1WGGuXNvDQi/N/AFZEJGyRvVJ00rnL6hkYHuPQyHjYUURE5lXkC/2cZfUAGkcXkciLfKGftzwo9G19h0NOIiIyvyJf6Evqq1jeWMWWXhW6iERb5AsdYENbE1t6B8OOISIyr8qi0Ne3N7Lz4FEGj+rAqIhEV1kU+oa2JgANu4hIpJVFob++rRFAwy4iEmllUegNVRWsbq3lqd3aQxeR6CqLQge4sK2Jp3sHcZ/6RZEiItFQPoW+qomB4TH6Do+GHUVEZF6UTaFftGoRAE/sejXkJCIi86NsCn3tsnqqKmI8+YoOjIpINJVNoVfEY6xf2cSTu7WHLiLRVDaFDvCGVU1s2zPEWCoddhQRkYIru0IfT2d4tm8o7CgiIgVXZoUeHBjVOLqIRFFZFfrShipWNFbxxCsaRxeR6CmrQodgL1176CISRWVY6E3sGTxG/5AuMBKRaCnDQs+Oo+/WXrqIREvZFfr5KxqoiJuGXUQkcvIqdDO7xsy2m1mPmd12im2uNLOnzGybmf26sDELp6oizroVjTypA6MiEjGzFrqZxYGvAZuAdcBNZrZuyjZNwNeB6939fODd85C1YN7Q3sSW3sOk0pmwo4iIFEw+e+gbgR533+Hu48BdwA1TtvkPwN3u/gqAu/cXNmZhvWFVE8cm0jy/bzjsKCIiBZNPoa8EdufM92aX5ToHWGRmD5rZ42b2vkIFnA8X6cCoiERQPoVu0yybepeIBPBG4PeAdwCfNrNzTnohs5vNrNvMugcGBuYctlDaFlXTUpfkSX2VrohESD6F3gu058y3AX3TbPNzdx9x9wPAQ8CGqS/k7pvdvcvdu1pbW0838xkzMy5sD+5gJCISFfkU+mPAGjPrNLMkcCNwz5Rtfgr8jpklzKwGuAR4rrBRC2t9WxM7DowwNDoRdhQRkYKYtdDdPQXcCtxPUNI/dPdtZnaLmd2S3eY54OfAFuBR4A533zp/sc/chvYm3GFrr24cLSLRkMhnI3e/D7hvyrLbp8x/Efhi4aLNr/UrGwF4uvcwb3pdS8hpRETOXNldKTppUW2SVYtreFpnuohIRJRtoUMw7LJFB0ZFJCLKu9DbGuk7PEr/sL55UURKX1kX+vq2JgC27NaBUREpfWVd6BesbCBmaNhFRCKhrAu9JpngnKX1PK1TF0UkAsq60AHWtzXydO8g7lO/zUBEpLSUfaFvaG9i8OgEuw8dCzuKiMgZUaFnD4zqe11EpNSVfaGvXVZPMhHTBUYiUvLKvtAr4jHOX9HAFh0YFZESV/aFDsGwyzN7dEs6ESltKnRgQ3sjxybS9AwcCTuKiMhpU6GjK0ZFJBpU6EBncy31lQmd6SIiJU2FDsRixvr2RhW6iJQ0FXrW+rYmnt87zOhEOuwoIiKnRYWetaGtkVTGeXbvUNhRREROiwo9a0P75IFRDbuISGlSoWcta6iitb5SFxiJSMlSoWeZGRvamnhKB0ZFpESp0HNc2N7IjoERXh0ZDzuKiMicqdBzXLq6GYBHdhwMOYmIyNzlVehmdo2ZbTezHjO7bYbtLjaztJn9u8JFXDgb2puoTcb5zUsHwo4iIjJnsxa6mcWBrwGbgHXATWa27hTb/QVwf6FDLpSKeIxLVjfzcI/20EWk9OSzh74R6HH3He4+DtwF3DDNdh8Ffgz0FzDfgnvT2c3sODBC36DuYCQipSWfQl8J7M6Z780uO87MVgK/D9w+0wuZ2c1m1m1m3QMDA3PNuiAuf10LAL/p0bCLiJSWfArdplk29Y7KXwY+6e4zXjfv7pvdvcvdu1pbW/PNuKDWLq2npa6SB18ozg8cEZFTSeSxTS/QnjPfBvRN2aYLuMvMAFqAa80s5e4/KUjKBRSLGW87bwn3btnLWCpNZSIediQRkbzks4f+GLDGzDrNLAncCNyTu4G7d7p7h7t3AD8C/lMplvmkq9ct5chYikd2HAo7iohI3mYtdHdPAbcSnL3yHPBDd99mZreY2S3zHTAMl7+uhZpknAee3Rd2FBGRvOUz5IK73wfcN2XZtAdA3f0DZx4rXFUVca5Y08oDz+7nz6+/gFhsusMIIiLFRVeKnsI1Fyxj/9AY3bteDTuKiEheVOin8Pbzl1KTjHP3E71hRxERyYsK/RRqkgk2XbCc/7dlr+5iJCIlQYU+g3970UqGx1I88Oz+sKOIiMxKhT6DS1c3s6KxirseeyXsKCIis1KhzyAWM95z6Vn8pucgPf3DYccREZmRCn0Wf3BxO8l4jO/9dlfYUUREZqRCn0VLXSXXbVjOjx7vZWh0Iuw4IiKnpELPw3+8vJOR8bT20kWkqKnQ83DBykbeuraVO/55B0fHU2HHERGZlgo9Tx+9ag2vHp3g+4/ojBcRKU4q9DxdtGoRb35dC998SHvpIlKcVOhz8Imr13DgyBh/89DLYUcRETmJCn0O3njWYq59/TK++dBL9A+Nhh1HROQEKvQ5+pN3nMtEOsOXHngh7CgiIidQoc9RR0st77usg7/v3s0Tr+irdUWkeKjQT8Mnrj6HZQ1V/Je7n2EinQk7jogIoEI/LXWVCf78hgt4ft8wf/PPO8KOIyICqNBP29XrlrLpgmV85R9f5KWBI2HHERFRoZ+Jz11/PtXJOB+/6ynGUxp6EZFwqdDPwNKGKr7wrvU8s+cw//MfddaLiIRLhX6GrrlgGTdtbOf2X7/Ewz0Hwo4jImVMhV4An75uHatbavnonU+yZ/BY2HFEpEzlVehmdo2ZbTezHjO7bZr17zGzLdnHw2a2ofBRi1dNMsHm93Uxnspwy/ce102lRSQUsxa6mcWBrwGbgHXATWa2bspmLwNvcff1wOeBzYUOWuzObq3jyzdeyNa+w3zsridJ6fx0EVlg+eyhbwR63H2Hu48DdwE35G7g7g+7++Rlk48AbYWNWRquOm8pn7luHfdv289//clW3D3sSCJSRhJ5bLMS2J0z3wtcMsP2HwJ+Nt0KM7sZuBlg1apVeUYsLR+8vJNDI+P89T/1kEzE+Nw7zycWs7BjiUgZyKfQp2ujaXc9zeytBIX+5unWu/tmssMxXV1dkd19/eOrz2E8leGbD+1gdCLNf3/XeuIqdRGZZ/kUei/QnjPfBvRN3cjM1gN3AJvc/WBh4pUmM+O2TedSVRHnK798kaFjKb70BxuoSebzxy0icnryGUN/DFhjZp1mlgRuBO7J3cDMVgF3A3/o7rrChqDUP3H1OXz6unXc/+w+/v03f8vewzqlUUTmz6yF7u4p4FbgfuA54Ifuvs3MbjGzW7KbfQZoBr5uZk+ZWfe8JS4xH3pzJ996fxc7DxzlnX/9Lzz0wkDYkUQkoiysMzG6urq8u7t8ev/F/cN85AdP8ML+I/zRFav5z29fSzKh67pEZG7M7HF375punRplgaxZWs89t76Z9166im8+tIPrv/ovPKkbZIhIAanQF1BVRZz/9m9ez7fe38XhYxO86xsP89mfbuXw0Ymwo4lIBKjQQ3DVeUv5xSeu4P2XdfDdR3ZxxRd/xeaHXtJXBojIGdEYesie2zvEF372PL9+YYCVTdX80VtW8+43tlOdjIcdTUSK0Exj6Cr0IvFwzwH+6hfbeeKVQZprk3zgTR2899KzWFSbDDuaiBQRFXqJcHce2/kq33iwh19tHyCZiLHpgmXcePEqLl29GDNdbSpS7mYqdF26WETMjI2di9nYuZHt+4b5/r/u4h+e3MNPn+qjs6WWd3e18c71K2hfXBN2VBEpQtpDL3LHxtPc98xe7nrsFR7bGZzmuKG9iXeuX86m1y9nZVN1yAlFZCFpyCUidh86yr1b9nLvlj629Q0BcO6yet6ytpW3rl3CG89aREVcJy6JRJkKPYJePjDC/dv28eD2frp3vkoq49RXJrhk9WI2di7mks5mzl/RQEIFLxIpKvSIGx6d4Dc9B/n1C/08suMQLx8YAaAmGeeNZy3i4o7FrG9r5PUrG2muqww5rYicCRV6mekfGuXRnYd49OXg8fy+4ePrVjZVB+WeLfi1y+ppravUGTQiJUJnuZSZJQ1VXLd+BdetXwEEe/Bb9wzxzJ5Bnu49zDO9h/nZ1n3Ht19UU8E5S+tZu6z+tecl9TTWVIT1nyAip0GFXgbqqyq47OxmLju7+fiywaPjbOsbYvu+YV7sH2b7vmHufmIPR8ZSx7dprk1yVnMNHS21dDTX0tFSS2dzLWe11NBQpbIXKTYacpHj3J2+w6O8sG+Y7fuH2XlghJ0HR9h54Cj7hkZP2HZxbZK2RdWsaKxm5aJqVjRVs7KpKvtczeLapIZxROaBhlwkL2bGymwhv/XcJSesOzaeZtehoNx3Hhxh18ER9gyO0jNwhF+/MMCxKV8sVpmIsbKpmiUNlSypr2JJfeXx6db6ymC+voqG6oSKX6RAVOiSl+pknHOXNXDusoaT1rk7g0cn2DN4jL7BY8ef+wZH2T80ylO7B+kfHmV0InPSz1YmYrTWV9JaX0lzbZJFNUkW1yZZVJtkce50dr6+KkFMN9wWmZYKXc6YmbEoW7wXrGycdht358hYiv7hMfqHxugfHmVgeIyB4TH6s899g6Ns6xvi4Mg446mTyx8gHjMW1VSwqCZJY3UFDdUVNFQlaKiuCOarKmioTmSfg/lguwT1VRXE9WEgEaZClwVhZtRXVVBfVcHZrXUzbuvuHJtIc2hk/Pjj1aPjHBqZ4NWRcQ4dHefQkXGGRifoHx6lpz/F0OgEQ8cmyMxySKiuMkF9VYLayuBRVxmnNpmgrjJBTWU8WJacXJezrDJBbTJBbc58ZSKm4SIpKip0KTpmRk0yQU0yQdui/L+ILJNxRsZTDI2mGDo2weFjQclPzg+NTi5LcXQ8xZGxFCNjKQ4MjzMyHkyPjKUZT0//r4OTc0J1RZzqijhVFXGqk/Hj85UVsWA6Of36qpzp6mQsWF8RpzIRJ5mIUXn8EbxWMh7TUJPMSoUukRGLvfavgDP50rLxVCYo9/Gg4CeLP/gQSDMyFnwYjE2kOTb5GM8wenw6zfBoioHhsePzxybSjE6kmUif/lllFXEjGY9RWRGnMhE7XvzJbPEH6yaXnbjN5AdFMm5UxGMk4idOT772dNMV8Vj2ceJ08BrBdDxm+tdKEVChi0yRTMRIJpLzcnORifRrxT86nsn5QAgKfyyVYSwVPI+nMjnP6Vnmg2VHR1JTlp247XxK5hR9RfYDY+qHQjxmJGLBB0AibiRisRPm4znzkx8UidiUn4tlt4tPWRaPnTCfmDJ/wmtlf3Zy/oSHGbEYOdPBczyefY4ZsePPFNUHmQpdZAFNFlt9CBdmuTvpjDORdsbTGSbSGVJpZyKdYTyP6Yl08EGRyviJ06lg3cSppnN+Pu2QzgTLRicypDJp0pngPdKZ4JHKOKl08NqT88Fz5nj+YhIzpnwY2MkfBjkfGDGDmzau4sO/s7rgWfIqdDO7BvgKEAfucPcvTFlv2fXXAkeBD7j7EwXOKiJnwCy7ZxqHakr3nrXuTsY5XvCpjJNOv1b8E+nMtB8E067P/tzkNhl30pngeEw6+wGY8dc+bNLZ5ZlMsN3x6SnbZE76Wch48F6ZjNMyT1+SN2uhm1kc+BpwNdALPGZm97j7szmbbQLWZB+XAN/IPouIFJSZETeIx0r3Q2m+5PNl2RuBHnff4e7jwF3ADVO2uQH4rgceAZrMbHmBs4qIyAzyKfSVwO6c+d7ssrlug5ndbGbdZtY9MDAw16wiIjKDfAp9ukO4U49K5LMN7r7Z3bvcvau1tTWffCIikqd8Cr0XaM+ZbwP6TmMbERGZR/kU+mPAGjPrNLMkcCNwz5Rt7gHeZ4FLgcPuvrfAWUVEZAaznuXi7ikzuxW4n+C0xW+7+zYzuyW7/nbgPoJTFnsITlv84PxFFhGR6eR1Hrq730dQ2rnLbs+ZduAjhY0mIiJzkc+Qi4iIlIDQbkFnZgPArtP88RbgQAHjFFKxZlOuuVGuuVGuuTmTXGe5+7SnCYZW6GfCzLpPdU+9sBVrNuWaG+WaG+Wam/nKpSEXEZGIUKGLiEREqRb65rADzKBYsynX3CjX3CjX3MxLrpIcQxcRkZOV6h66iIhMoUIXEYmIkit0M7vGzLabWY+Z3bbA7/1tM+s3s605yxab2QNm9mL2eVHOuk9lc243s3fMY652M/uVmT1nZtvM7GPFkM3MqszsUTN7Opvrz4ohV857xc3sSTO7t1hymdlOM3vGzJ4ys+4iytVkZj8ys+ezv2eXhZ3LzNZm/5wmH0Nm9vGwc2Xf5xPZ3/mtZnZn9v+F+c/l7iXzIPgumZeA1UASeBpYt4DvfwVwEbA1Z9lfArdlp28D/iI7vS6brxLozOaOz1Ou5cBF2el64IXs+4eajeBrleuy0xXAvwKXhp0rJ98fAz8A7i2iv8udQMuUZcWQ62+BD2enk0BTMeTKyRcH9gFnhZ2L4F4QLwPV2fkfAh9YiFzz9gc8T39plwH358x/CvjUAmfo4MRC3w4sz04vB7ZPl43gy80uW6CMPyW4ZWDRZANqgCcIbk0Yei6Cr3j+JfC7vFboxZBrJycXeqi5gIZsQVkx5ZqS5e3Ab4ohF6/d8Gcxwfdl3ZvNN++5Sm3IJa87Iy2wpZ79quDs85Ls8lCymlkH8AaCveHQs2WHNZ4C+oEH3L0ocgFfBv4EyOQsK4ZcDvzCzB43s5uLJNdqYAD439khqjvMrLYIcuW6EbgzOx1qLnffA/wV8Aqwl+DrxH+xELlKrdDzujNSkVjwrGZWB/wY+Li7D8206TTL5iWbu6fd/UKCPeKNZnZB2LnM7Dqg390fz/dHplk2X3+Xl7v7RQQ3Xv+ImV0xw7YLlStBMNT4DXd/AzBCMGQQdq7gzYL7NFwP/J/ZNp1m2Xz8fi0iuM9yJ7ACqDWz9y5ErlIr9GK8M9J+y94QO/vcn12+oFnNrIKgzL/v7ncXUzYAdx8EHgSuKYJclwPXm9lOgpue/66Z/V0R5MLd+7LP/cA/ENykPexcvUBv9l9XAD8iKPiwc03aBDzh7vuz82HnehvwsrsPuPsEcDfwpoXIVWqFns/dkxbaPcD7s9PvJxi/nlx+o5lVmlknsAZ4dD4CmJkB3wKec/cvFUs2M2s1s6bsdDXBL/rzYedy90+5e5u7dxD8Dv2Tu7837FxmVmtm9ZPTBOOuW8PO5e77gN1mtja76Crg2bBz5biJ14ZbJt8/zFyvAJeaWU32/82rgOcWJNd8HqiYp4Mf1xKcxfES8KcL/N53EoyJTRB8qn4IaCY4uPZi9nlxzvZ/ms25Hdg0j7neTPBPtC3AU9nHtWFnA9YDT2ZzbQU+k10e+p9ZzvtdyWsHRcP+81pNcLbD08C2yd/vsHNl3+dCoDv7d/kTYFGR5KoBDgKNOcuKIdefEey8bAW+R3AGy7zn0qX/IiIRUWpDLiIicgoqdBGRiFChi4hEhApdRCQiVOgiIhGhQhcRiQgVuohIRPx/i1vJqc2M+iIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUG0lEQVR4nO3df6zdd33f8edrTqwtadastQlZbHCYoq4UkRBdOWFBxFkXcDLArdRJtlhADGRRJRmrtrKwSom1iVGJqQMKnRWBl6JBogmSYpX8VNY0UJbKx1nIT5JaIW1undUX0oVflTK37/1xvmaH63N9juNz7zn3c58P6eqe7+fz+X7P++vj87rf+7nfez+pKiRJ7fpb0y5AkrS8DHpJapxBL0mNM+glqXEGvSQ17rRpFzDMhg0basuWLdMuQ5JWjYMHD36nqjYO65vJoN+yZQu9Xm/aZUjSqpHkT5fqc+pGkhpn0EtS4wx6SWqcQS9JjTPoJalxI4M+yeYkf5DkqSRPJPnQkDFJ8qkkh5I8muTigb7tSZ7u+m6Y9AmsNg9s2zP7x9wz2eMtxzlP2qRrXIvnPGmr4r2ySmTUX69Mci5wblU9nOQs4CDwS1X15MCYq4HrgauBS4BPVtUlSdYBzwBXAvPAAWDX4L7DzM3NVbO3VyYw6b8YOuljzvrxloPnPHtWw3tlhiQ5WFVzw/pGXtFX1QtV9XD3+PvAU8B5i4btAD5ffQ8BZ3dfILYCh6rq2ap6GbitGytJWiEnNUefZAvwJuCPF3WdBzw/sD3ftS3VPuzYu5P0kvQWFhZOpqyZ98C2Pf0riaTf0D0+lW8jJ37MPcOP90qncZbjnCdt0jWuxXOetFXxXlmFRk7d/Hhg8lPAHwIfrarbF/V9FfhYVX29274f+DDwOuDtVfWBrv0aYGtVXX+i53LqZsrHnPXjLQfPefashvfKDDnR1M1YfwIhyenAl4EvLA75zjyweWB7E3AYWL9EuyRphYxz102AzwFPVdVvLTFsP/Ce7u6bS4GXquoF+j98vSDJ+UnWAzu7sWvWA5ffNPvHvGmyx1uOc560Sde4Fs950lbFe2WVGOeum7cAXwMeA/6ma/53wGsAqmpv98Xg08B24EfA+6qq1+1/NfAJYB2wr6o+OqqopqduJGkZnNLUTTfvnhFjCrh2ib47gTvHqFOStAz8zVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuNGLjySZB/wDuBIVb1hSP+vA+8eON7PAxur6sUkzwHfB/4aOLrU6ieSpOUzzhX9LfSXCByqqj5eVRdV1UXAR4A/rKoXB4Zc0fUb8pI0BSODvqoeBF4cNa6zC7j1lCqSJE3UxObok5xB/8r/ywPNBdyb5GCS3SP2352kl6S3sLAwqbIkac2b5A9j3wn80aJpm8uq6mLgKuDaJG9dauequrmq5qpqbuPGjRMsS5LWtkkG/U4WTdtU1eHu8xHgDmDrBJ9PkjSGiQR9kp8GLge+MtB2ZpKzjj0G3gY8PonnkySNb5zbK28FtgEbkswDNwGnA1TV3m7YLwP3VtUPB3Y9B7gjybHn+WJV3T250iVJ4xgZ9FW1a4wxt9C/DXOw7VngwldamCRpMvzNWElqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS40YGfZJ9SY4kGboMYJJtSV5K8kj3ceNA3/YkTyc5lOSGSRYuSRrPOFf0twDbR4z5WlVd1H38e4Ak64DPAFcBrwd2JXn9qRQrSTp5I4O+qh4EXnwFx94KHKqqZ6vqZeA2YMcrOI4k6RRMao7+zUm+meSuJL/QtZ0HPD8wZr5rGyrJ7iS9JL2FhYUJlSVJmkTQPwy8tqouBH4b+L2uPUPG1lIHqaqbq2ququY2btw4gbIkSTCBoK+q71XVD7rHdwKnJ9lA/wp+88DQTcDhU30+SdLJOeWgT/LqJOkeb+2O+V3gAHBBkvOTrAd2AvtP9fkkSSfntFEDktwKbAM2JJkHbgJOB6iqvcCvAL+a5CjwV8DOqirgaJLrgHuAdcC+qnpiWc5CkrSk9DN5tszNzVWv15t2GZK0aiQ5WFVzw/r8zVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaNzLok+xLciTJ40v0vzvJo93HN5JcOND3XJLHkjySxD8wL0lTMM4V/S3A9hP0fxu4vKreCPwH4OZF/VdU1UVL/UF8SdLyGrmUYFU9mGTLCfq/MbD5EP1FwCVJM2LSc/TvB+4a2C7g3iQHk+w+0Y5JdifpJektLCxMuCxJWrtGXtGPK8kV9IP+LQPNl1XV4SSvAu5L8q2qenDY/lV1M920z9zc3OwtZCtJq9REruiTvBH4LLCjqr57rL2qDnefjwB3AFsn8XySpPGdctAneQ1wO3BNVT0z0H5mkrOOPQbeBgy9c0eStHxGTt0kuRXYBmxIMg/cBJwOUFV7gRuBnwV+JwnA0e4Om3OAO7q204AvVtXdy3AOkqQTGOeum10j+j8AfGBI+7PAhcfvIUlaSf5mrCQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcSODPsm+JEeSDF0GMH2fSnIoyaNJLh7o257k6a7vhkkWvlIe2LZn2iWsuD17pl2BVqO1+F5ZLVJVJx6QvBX4AfD5qnrDkP6rgeuBq4FLgE9W1SVJ1gHPAFcC88ABYFdVPTmqqLm5uer1eid7LssjgRH/Rq1Zg6esSfA/zlQlOdgt43qckVf0VfUg8OIJhuyg/0Wgquoh4Owk5wJbgUNV9WxVvQzc1o2VJK2gSczRnwc8P7A937Ut1T5Ukt1Jekl6CwsLEyjrlXtg257+1Ul/YfMfP275W9M9e4aestM4OqG1+F5ZjUZO3QAk2QL8/hJTN18FPlZVX++27wc+DLwOeHu3eDhJrgG2VtX1o57PqZvpWoOnrEnwP85UnWjq5rQJHH8e2DywvQk4DKxfol2StIImMXWzH3hPd/fNpcBLVfUC/R++XpDk/CTrgZ3d2FXlgctvmnYJK+6mtXfKmoC1+F5ZLca56+ZWYBuwAfgL4CbgdICq2pskwKeB7cCPgPdVVa/b92rgE8A6YF9VfXScomZq6kaSVoFTmrqpql0j+gu4dom+O4E7xylSkrQ8/M1YSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Ljxgr6JNuTPJ3kUJIbhvT/epJHuo/Hk/x1kp/p+p5L8ljX57JRkrTCRq4wlWQd8BngSvoLgR9Isr+qnjw2pqo+Dny8G/9O4Neq6sWBw1xRVd+ZaOWSpLGMc0W/FThUVc9W1cvAbcCOE4zfBdw6ieIkSadunKA/D3h+YHu+aztOkjPoLxL+5YHmAu5NcjDJ7qWeJMnuJL0kvYWFhTHKkiSNY5ygz5C2WmLsO4E/WjRtc1lVXQxcBVyb5K3Ddqyqm6tqrqrmNm7cOEZZkqRxjBP088Dmge1NwOElxu5k0bRNVR3uPh8B7qA/FSRJWiHjBP0B4IIk5ydZTz/M9y8elOSngcuBrwy0nZnkrGOPgbcBj0+icEnSeEbedVNVR5NcB9wDrAP2VdUTST7Y9e/thv4ycG9V/XBg93OAO5Ice64vVtXdkzwBSdKJpWqp6fbpmZubq17PW+4laVxJDlbV3LA+fzNWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxo0V9Em2J3k6yaEkNwzp35bkpSSPdB83jruvJGl5jVxhKsk64DPAlfTXjz2QZH9VPblo6Neq6h2vcF9J0jIZ54p+K3Coqp6tqpeB24AdYx7/VPaVJE3AOEF/HvD8wPZ817bYm5N8M8ldSX7hJPclye4kvSS9hYWFMcqSJI1jnKDPkLbFC80+DLy2qi4Efhv4vZPYt99YdXNVzVXV3MaNG8coS5I0jnGCfh7YPLC9CTg8OKCqvldVP+ge3wmcnmTDOPtKkpbXOEF/ALggyflJ1gM7gf2DA5K8Okm6x1u74353nH0lSctr5F03VXU0yXXAPcA6YF9VPZHkg13/XuBXgF9NchT4K2BnVRUwdN9lOhdJ0hDp5/FsmZubq16vN+0yJGnVSHKwquaG9fmbsZLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxo0V9Em2J3k6yaEkNwzpf3eSR7uPbyS5cKDvuSSPJXkkiauJSNIKG7mUYJJ1wGeAK+kv9n0gyf6qenJg2LeBy6vqL5NcBdwMXDLQf0VVfWeCdUuSxjTOFf1W4FBVPVtVLwO3ATsGB1TVN6rqL7vNh4BNky1TkvRKjRP05wHPD2zPd21LeT9w18B2AfcmOZhk91I7JdmdpJekt7CwMEZZkqRxjJy6ATKkbeiK4kmuoB/0bxlovqyqDid5FXBfkm9V1YPHHbDqZvpTPszNzc3eiuWStEqNc0U/D2we2N4EHF48KMkbgc8CO6rqu8faq+pw9/kIcAf9qSBJ0goZJ+gPABckOT/JemAnsH9wQJLXALcD11TVMwPtZyY569hj4G3A45MqXpI02sipm6o6muQ64B5gHbCvqp5I8sGufy9wI/CzwO8kAThaVXPAOcAdXdtpwBer6u5lORNJ0lCpmr3p8Lm5uer1vOVeksaV5GB3gX0cfzNWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4sYI+yfYkTyc5lOSGIf1J8qmu/9EkF4+776Q9sG3Pcj+FZsBae53X2vmuFpN+XZbrdR65wlSSdcAzwJX0Fwo/AOyqqicHxlwNXA9cDVwCfLKqLhln32FOaYWpBGZw1SxN2Fp7ndfa+a4Wk35dTuF4p7rC1FbgUFU9W1UvA7cBOxaN2QF8vvoeAs5Ocu6Y+0qSltE4QX8e8PzA9nzXNs6YcfYFIMnuJL0kvYWFhTHK+v8e2Lan/5Wwvwj5jx/77W5b1trrvNbOd7WY9OuyEq/zOFM3/wx4e1V9oNu+BthaVdcPjPkq8LGq+nq3fT/wYeB1o/YdxqkbjbTWXue1dr6rxSqZujltjP3ngc0D25uAw2OOWT/GvpKkZTTO1M0B4IIk5ydZD+wE9i8asx94T3f3zaXAS1X1wpj7TtQDl9+0nIfXjFhrr/NaO9/VYtKvy3K9ziOnbuDHd9V8AlgH7Kuqjyb5IEBV7U0S4NPAduBHwPuqqrfUvqOe75SmbiRpDTrR1M1YQb/SDHpJOjmnenulJGkVM+glqXEGvSQ1zqCXpMbN5A9jkywAf/oKd98AfGeC5UzarNcH1jgJs14fzH6Ns14fzFaNr62qjcM6ZjLoT0WS3lI/eZ4Fs14fWOMkzHp9MPs1znp9sDpqBKduJKl5Br0kNa7FoL952gWMMOv1gTVOwqzXB7Nf46zXB6ujxvbm6CVJP6nFK3pJ0gCDXpIa10zQr/Qi5CcryeYkf5DkqSRPJPnQtGsaJsm6JP8rye9Pu5Zhkpyd5EtJvtX9W7552jUtluTXutf48SS3JvnbU65nX5IjSR4faPuZJPcl+ZPu89+bwRo/3r3Ojya5I8nZs1bjQN+/SVJJNkyjtlGaCPpuEfLPAFcBrwd2JXn9dKs6zlHgX1fVzwOXAtfOYI0AHwKemnYRJ/BJ4O6q+ofAhcxYrUnOA/4lMFdVb6D/57l3TrcqbqH/J8QH3QDcX1UXAPd329N0C8fXeB/whqp6I/AM8JGVLmqRWzi+RpJsBq4E/mylCxpXE0HPKliEvKpeqKqHu8ffpx9QQ9fPnZYkm4B/Cnx22rUMk+TvAm8FPgdQVS9X1f+ZblVDnQb8nSSnAWcw5VXVqupB4MVFzTuA3+0e/y7wSyta1CLDaqyqe6vqaLf5EP0V6qZmiX9HgP9Mf+nUmb2zpZWgH3sR8lmQZAvwJuCPp1vJcT5B/z/s30y7kCW8DlgA/ms3vfTZJGdOu6hBVfXnwH+if3X3Av3V1u6dblVDndOtAkf3+VVTrmeUfwHcNe0iFkvyLuDPq+qb067lRFoJ+gxpm8mvrkl+Cvgy8K+q6nvTrueYJO8AjlTVwWnXcgKnARcD/6Wq3gT8kOlPOfyEbq57B3A+8PeBM5P88+lWtbol+Q36U59fmHYtg5KcAfwGcOO0axmllaAfZwHzqUtyOv2Q/0JV3T7teha5DHhXkufoT3394yT/bbolHWcemK+qY98JfYl+8M+SfwJ8u6oWqur/ArcD/2jKNQ3zF0nOBeg+H5lyPUMleS/wDuDdNXu/9PMP6H9B/2b3vtkEPJzk1VOtaohWgn7FFyE/Wd26up8Dnqqq35p2PYtV1UeqalNVbaH/7/c/qmqmrkSr6n8Dzyf5ua7pF4Enp1jSMH8GXJrkjO41/0Vm7AfGnf3Ae7vH7wW+MsVahkqyHfi3wLuq6kfTrmexqnqsql5VVVu69808cHH3/3SmNBH03Q9srgPuof+m+u9V9cR0qzrOZcA19K+UH+k+rp52UavQ9cAXkjwKXAT8xynX8xO67za+BDwMPEb/PTbVX5NPcivwP4GfSzKf5P3AbwJXJvkT+neM/OYM1vhp4Czgvu79sncGa1wV/BMIktS4Jq7oJUlLM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4/4fpMXWK187k5gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times 1:\n",
      "   fit_time  score_time  test_accuracy  train_accuracy  test_neg_log_loss  \\\n",
      "0  0.281000    0.003999        0.93750        0.984375          -0.083018   \n",
      "1  0.291558    0.004002        0.90625        1.000000          -0.453981   \n",
      "2  0.274399    0.003028        1.00000        0.992188          -0.008396   \n",
      "3  0.257996    0.002999        0.96875        0.984375          -0.076209   \n",
      "4  0.264798    0.004001        0.93750        1.000000          -0.395948   \n",
      "\n",
      "   train_neg_log_loss  \n",
      "0           -0.025497  \n",
      "1           -0.004920  \n",
      "2           -0.024652  \n",
      "3           -0.025258  \n",
      "4           -0.007049  \n",
      "Train Log Loss Mean:  0.017474961115484584\n",
      "Test Log Loss Mean:  0.20351041504303286\n",
      "Train Accuracy Mean:  0.9921875\n",
      "Test Accuracy Mean:  0.95\n",
      "\n",
      "Estimator Loss:  0.01751493753714674\n",
      "Times 2:\n",
      "   fit_time  score_time  test_accuracy  train_accuracy  test_neg_log_loss  \\\n",
      "0  0.266831    0.003000        0.90625        0.992188          -0.149603   \n",
      "1  0.278620    0.003999        0.93750        1.000000          -0.350890   \n",
      "2  0.268002    0.002997        0.96875        0.984375          -0.057744   \n",
      "3  0.269591    0.003001        0.96875        0.992188          -0.053201   \n",
      "4  0.273710    0.002997        0.90625        1.000000          -0.351833   \n",
      "\n",
      "   train_neg_log_loss  \n",
      "0           -0.019700  \n",
      "1           -0.008044  \n",
      "2           -0.022382  \n",
      "3           -0.019747  \n",
      "4           -0.011072  \n",
      "Train Log Loss Mean:  0.016189215474501747\n",
      "Test Log Loss Mean:  0.19265425800951355\n",
      "Train Accuracy Mean:  0.99375\n",
      "Test Accuracy Mean:  0.9375\n",
      "\n",
      "Estimator Loss:  0.0162314391532409\n",
      "Times 3:\n",
      "   fit_time  score_time  test_accuracy  train_accuracy  test_neg_log_loss  \\\n",
      "0  0.273999       0.004        1.00000        0.984375          -0.028636   \n",
      "1  0.269001       0.003        0.96875        0.984375          -0.051289   \n",
      "2  0.255760       0.003        0.93750        0.992188          -0.186848   \n",
      "3  0.259603       0.003        1.00000        0.984375          -0.015278   \n",
      "4  0.265998       0.004        0.90625        1.000000          -0.411356   \n",
      "\n",
      "   train_neg_log_loss  \n",
      "0           -0.024536  \n",
      "1           -0.026628  \n",
      "2           -0.020898  \n",
      "3           -0.026579  \n",
      "4           -0.004411  \n",
      "Train Log Loss Mean:  0.02061057638237487\n",
      "Test Log Loss Mean:  0.1386814350891935\n",
      "Train Accuracy Mean:  0.9890625\n",
      "Test Accuracy Mean:  0.9625\n",
      "\n",
      "Estimator Loss:  0.020658388385121802\n",
      "Times 4:\n",
      "   fit_time  score_time  test_accuracy  train_accuracy  test_neg_log_loss  \\\n",
      "0  0.300678    0.003001        0.90625        1.000000          -0.509965   \n",
      "1  0.265577    0.003999        0.87500        1.000000          -0.712108   \n",
      "2  0.257003    0.004000        0.96875        0.992188          -0.098664   \n",
      "3  0.258000    0.003000        1.00000        0.984375          -0.020432   \n",
      "4  0.257473    0.003000        0.96875        0.992188          -0.051111   \n",
      "\n",
      "   train_neg_log_loss  \n",
      "0           -0.005409  \n",
      "1           -0.003595  \n",
      "2           -0.019432  \n",
      "3           -0.027362  \n",
      "4           -0.043498  \n",
      "Train Log Loss Mean:  0.019859082164672612\n",
      "Test Log Loss Mean:  0.2784557064106873\n",
      "Train Accuracy Mean:  0.99375\n",
      "Test Accuracy Mean:  0.94375\n",
      "\n",
      "Estimator Loss:  0.01989250060478396\n",
      "Times 5:\n",
      "   fit_time  score_time  test_accuracy  train_accuracy  test_neg_log_loss  \\\n",
      "0  0.282910    0.003000        0.93750        1.000000          -0.409363   \n",
      "1  0.269074    0.002999        0.96875        0.992188          -0.051621   \n",
      "2  0.271317    0.003001        0.90625        0.992188          -0.315329   \n",
      "3  0.264158    0.003000        0.90625        1.000000          -0.366689   \n",
      "4  0.292099    0.003000        1.00000        0.992188          -0.009789   \n",
      "\n",
      "   train_neg_log_loss  \n",
      "0           -0.007467  \n",
      "1           -0.020342  \n",
      "2           -0.017497  \n",
      "3           -0.008545  \n",
      "4           -0.022926  \n",
      "Train Log Loss Mean:  0.015355352184398935\n",
      "Test Log Loss Mean:  0.2305583141757194\n",
      "Train Accuracy Mean:  0.9953125\n",
      "Test Accuracy Mean:  0.94375\n",
      "\n",
      "Estimator Loss:  0.01539526812110241\n",
      "Best Test Accuracy:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BestClassifier_Sun Nov 21 16_20_41 2021_acc_1.0.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import joblib, time\n",
    "import sklearn\n",
    "import sklearn.neural_network as nn\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "path = u\"midterm_hw_dataset/classification/train/3_train_classification.csv\"\n",
    "df = pd.read_csv(path)\n",
    "m, n = df.shape\n",
    "X = df.iloc[:, 0 : n - 1]\n",
    "Y = df.iloc[:, n - 1]\n",
    "X_type = list(X.columns)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "warnings.filterwarnings('ignore', category=Warning, module='sklearn')\n",
    "\n",
    "steps = [\n",
    "\t('scaler', StandardScaler()), \n",
    "\t('classifier', nn.MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=rng,\\\n",
    "\tearly_stopping=False, activation='relu', learning_rate_init=0.007, tol=1e-08, max_iter=800, verbose=0))\n",
    "]\n",
    "clf_pipe = Pipeline(steps=steps)\n",
    "clf_pipe.fit(X_train, Y_train)\n",
    "acc = clf_pipe.score(X_test, Y_test)\n",
    "print(acc)\n",
    "plt.plot(clf_pipe[1].loss_curve_)\n",
    "plt.show()\n",
    "Y_pred = clf_pipe.predict(X_test)\n",
    "plt.plot(np.arange(len(Y_test)), Y_pred, 'b+', np.arange(len(Y_test)), Y_test, 'r+')\n",
    "plt.show()\n",
    "\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(Y_test, Y_pred, labels=clf_pipe[1].classes_), display_labels=clf_pipe[1].classes_)\n",
    "cm.plot()\n",
    "plt.show()\n",
    "\n",
    "# Five times CV\n",
    "cv_results_dict={}\n",
    "estimator_dict = {}\n",
    "scoring_dict={}\n",
    "best_test_acc = acc\n",
    "best_estimator = clf_pipe\n",
    "\n",
    "for i in range(5):\n",
    "\tprint(\"Times %d:\" % (i + 1))\n",
    "\tcv_results = cross_validate(clf_pipe, X, Y, cv=KFold(n_splits=5, shuffle=True, random_state=i), scoring=['accuracy', 'neg_log_loss'], return_train_score=True, return_estimator=True)\n",
    "\tcv_results = pd.DataFrame(cv_results)\n",
    "\tcv_results_dict[i] = cv_results\n",
    "\testimators = cv_results['estimator']\n",
    "\testimator_dict[i] = estimators\n",
    "\t\n",
    "\ttrain_logloss_mean = cv_results['train_neg_log_loss'].mean() * (-1.0)\n",
    "\ttest_logloss_mean = cv_results['test_neg_log_loss'].mean() * (-1.0)\n",
    "\ttrain_acc_mean = cv_results['train_accuracy'].mean()\n",
    "\ttest_acc_mean = cv_results['test_accuracy'].mean()\n",
    "\tscoring_dict[i] = {'train_logloss_mean': train_logloss_mean,\n",
    "\t\t\t\t\t\t'test_logloss_mean': test_logloss_mean,\n",
    "\t\t\t\t\t\t'train_acc_mean': train_acc_mean,\n",
    "\t\t\t\t\t\t'test_acc_mean': test_acc_mean}\n",
    "\tprint(cv_results.drop(columns=['estimator']))\n",
    "\t\n",
    "\tcurrent_smallest_test_acc = np.max(cv_results['test_accuracy'])\n",
    "\tif current_smallest_test_acc > best_test_acc:\n",
    "\t\tcurrent_smallest_test_acc_idx = np.argmax(cv_results['test_accuracy'])\n",
    "\t\tcurrent_smallest_estimator = estimators[current_smallest_test_acc_idx]\n",
    "\t\tbest_estimator = current_smallest_estimator\n",
    "\t\tbest_test_acc = current_smallest_test_acc\n",
    "\t\n",
    "\tprint(\"Train Log Loss Mean: \", train_logloss_mean)\n",
    "\tprint(\"Test Log Loss Mean: \", test_logloss_mean)\n",
    "\tprint(\"Train Accuracy Mean: \", train_acc_mean)\n",
    "\tprint(\"Test Accuracy Mean: \", test_acc_mean)\n",
    "\t\n",
    "\tloss_list = []\n",
    "\tfor est in estimators:\n",
    "\t\tloss_list.append(est[1].loss_)\n",
    "\testimator_loss_mean = np.array(loss_list).mean()\n",
    "\t\n",
    "\tprint(\"\\nEstimator Loss: \", estimator_loss_mean)\n",
    "\n",
    "print(\"Best Test Accuracy: \", best_test_acc)\n",
    "\n",
    "date = time.asctime()\n",
    "date = date.replace(\":\", \"_\")\n",
    "best_estimator.fit(X, Y)\n",
    "acc = best_estimator.score(X, Y)\n",
    "joblib.dump(best_estimator, f\"BestClassifier_{date}_acc_{acc}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d06178",
   "metadata": {},
   "source": [
    "运用MLP多层感知机作为分类器，五折交叉验证损失和准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf92744",
   "metadata": {},
   "source": [
    "导出上述测试最好情况下的pkl文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804eba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "path = u\"3_test_classification.csv\"    #测试接口，此处放置测试文件路径\n",
    "df = pd.read_csv(path)\n",
    "m, n = df.shape\n",
    "X = df.iloc[:, 0 : n - 1]\n",
    "Y = df.iloc[:, n - 1]\n",
    "\n",
    "reg = joblib.load(\"BestClassifier_Sun Nov 21 16_20_41 2021_acc_1.0.pkl\")\n",
    "print(accuracy_score(Y, reg.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096d1ac",
   "metadata": {},
   "source": [
    "以上是测试程序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee0172c",
   "metadata": {},
   "source": [
    "clf = joblib.load(\"BestClassifier_Sun Nov 21 16_20_41 2021_acc_1.0.pkl\") # 此为模型加载步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb5dbd",
   "metadata": {},
   "source": [
    "以下为测试函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89becef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierTestXY(modelpath, X_test, Y_test):\n",
    "\t\"\"\"\n",
    "\tClassifier Test Interface\n",
    "\t\n",
    "\t===================================\n",
    "\tInput:\n",
    "\t===================================\n",
    "\tmodelpath: Model File's Path (.pkl)\n",
    "\tX_test: Test Data of X Columns, shape: (m, n) of np.ndarray / pd.DataFrame\n",
    "\tY_test: Test Data of Y Columns, shape: (m,) of np.ndarray / pd.Series\n",
    "\t\n",
    "\t===================================\n",
    "\tInternal Dataset Variables (for debug use)\n",
    "\t===================================\n",
    "\testimator: Pipeline or estimators implemented :meth: predict\n",
    "\tY_pred: predictions from X_test with the estimator inputed, shape: (m,)\n",
    "\t\n",
    "\t===================================\n",
    "\tReturn:\n",
    "\t===================================\n",
    "\tacc: Accuracy\n",
    "\t\"\"\"\n",
    "\t\n",
    "\timport joblib\n",
    "\testimator = joblib.load(modelpath)\n",
    "\tY_pred = estimator.predict(X_test)\n",
    "\tfrom sklearn.metrics import accuracy_score\n",
    "\tacc = accuracy_score(Y_test, Y_pred)\n",
    "\t\n",
    "\treturn acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956445f6",
   "metadata": {},
   "source": [
    "以下为用例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62aab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = u\"3_test_classification.csv\"    #测试接口，此处放置测试文件路径\n",
    "df = pd.read_csv(path)\n",
    "m, n = df.shape\n",
    "X = df.iloc[:, 0 : n - 1]\n",
    "Y = df.iloc[:, n - 1]\n",
    "\n",
    "acc = ClassifierTestXY(\"BestClassifier_Sun Nov 21 16_20_41 2021_acc_1.0.pkl\", X, Y)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
